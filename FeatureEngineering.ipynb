{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "48844dff-a9a0-40fc-b10e-6503d3f94599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "output_dir = Path(\"engineered_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "figures_dir = Path(\"figures/engineered_features\")\n",
    "figures_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d155266b-738d-416a-af7d-8754455c0e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dfs = {}\n",
    "all_features = []\n",
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    required_cols = [\n",
    "        'HOME_LAST_N_WIN_PCT', 'AWAY_LAST_N_WIN_PCT',\n",
    "        'HOME_LAST_N_AVG_PTS', 'AWAY_LAST_N_AVG_PTS_ALLOWED',\n",
    "        'WIN_PCT_HOME', 'WIN_PCT_AWAY', 'FG_PCT_home', 'FG_PCT_away',\n",
    "        'AST_home', 'AST_away', 'REB_home', 'REB_away'\n",
    "    ]\n",
    "    if not all(col in df.columns for col in required_cols):\n",
    "        return None\n",
    "\n",
    "    \n",
    "\n",
    "    # Binned win % for categorical splits\n",
    "    df['home_win_bin'] = pd.cut(df['WIN_PCT_HOME'], bins=[0, 0.4, 0.6, 0.8, 1.0], labels=[0, 1, 2, 3]).astype(int)\n",
    "    df['away_win_bin'] = pd.cut(df['WIN_PCT_AWAY'], bins=[0, 0.4, 0.6, 0.8, 1.0], labels=[0, 1, 2, 3]).astype(int)\n",
    "\n",
    "    # Fundamental gaps\n",
    "    df['win_pct_gap'] = df['HOME_LAST_N_WIN_PCT'] - df['AWAY_LAST_N_WIN_PCT']\n",
    "    df['scoring_gap'] = df['HOME_LAST_N_AVG_PTS'] - df['AWAY_LAST_N_AVG_PTS_ALLOWED']\n",
    "    df['defense_gap'] = df['AWAY_LAST_N_AVG_PTS_ALLOWED'] - df.get('HOME_LAST_N_AVG_PTS_ALLOWED', 100)\n",
    "    df['momentum_score'] = df['win_pct_gap'] + df['scoring_gap'] - df['defense_gap']\n",
    "\n",
    "    # Assist-Rebound Ratios\n",
    "    df['AST_REB_ratio_home'] = df['AST_home'] / (df['REB_home'] + 1e-5)\n",
    "    df['AST_REB_ratio_away'] = df['AST_away'] / (df['REB_away'] + 1e-5)\n",
    "    df['AST_REB_ratio_diff'] = df['AST_REB_ratio_home'] - df['AST_REB_ratio_away']\n",
    "\n",
    "    # Shooting x AST synergy\n",
    "    df['home_ast_shooting_synergy'] = df['AST_home'] * df['FG_PCT_home']\n",
    "    df['away_ast_shooting_synergy'] = df['AST_away'] * df['FG_PCT_away']\n",
    "    df['shooting_variance_gap'] = (df['FG_PCT_home'] - df['FG_PCT_away']) ** 2\n",
    "    df['combined_shooting'] = df['FG_PCT_home'] * df['FG_PCT_away']\n",
    "\n",
    "    # Higher-order nonlinear combos\n",
    "    df['FG_PCT_home_x_AST_home'] = df['FG_PCT_home'] * df['AST_home']\n",
    "    df['REB_home_minus_away'] = df['REB_home'] - df['REB_away']\n",
    "    df['home_shooting_synergy'] = df['FG_PCT_home'] * df['AST_REB_ratio_home']\n",
    "    df['away_shooting_synergy'] = df['FG_PCT_away'] * df['AST_REB_ratio_away']\n",
    "    df['scoring_defense_ratio'] = df['scoring_gap'] / (df['defense_gap'] + 1e-5)\n",
    "    \n",
    "    df['high_ast_home'] = (df['AST_home'] > 25).astype(int)\n",
    "    df['shooting_edge'] = (df['FG_PCT_home'] > df['FG_PCT_away']).astype(int)\n",
    "    df['rebound_edge'] = (df['REB_home'] > df['REB_away']).astype(int)\n",
    "    df['is_momentum_positive'] = (df['momentum_score'] > 0).astype(int)\n",
    "    # Advanced nonlinearity\n",
    "    df['momentum_log_gap'] = df['momentum_score'] * np.log1p(np.abs(df['win_pct_gap']))\n",
    "    df['reb_gap_squared'] = (df['REB_home'] - df['REB_away']) ** 2\n",
    "    df['ast_gap_squared'] = (df['AST_home'] - df['AST_away']) ** 2\n",
    "    df['home_strength_ratio'] = df['WIN_PCT_HOME'] / (df['WIN_PCT_AWAY'] + 1e-5)\n",
    "    df['win_pct_gap_squared'] = df['win_pct_gap'] ** 2\n",
    "    df['scoring_gap_squared'] = df['scoring_gap'] ** 2\n",
    "    df['log_defense_gap'] = np.log1p(np.abs(df['defense_gap']))\n",
    "    df['log_momentum_score'] = np.log1p(np.abs(df['momentum_score']))\n",
    "    df['log_AST_home'] = np.log1p(df['AST_home'])\n",
    "    df['squared_FG_PCT_home'] = df['FG_PCT_home'] ** 2\n",
    "    df['exp_momentum'] = np.exp(df['momentum_score'])\n",
    "    df['reciprocal_defense_gap'] = 1 / (df['defense_gap'] + 1e-5)\n",
    "    df['asymmetry_shooting'] = np.abs(df['FG_PCT_home'] - df['FG_PCT_away'])\n",
    "\n",
    "    df['momentum_win_interaction'] = df['momentum_score'] * df['win_pct_gap']\n",
    "    df['ast_shooting_synergy_home'] = df['AST_home'] * df['FG_PCT_home']\n",
    "    df['ast_shooting_synergy_away'] = df['AST_away'] * df['FG_PCT_away']\n",
    "    df['reb_ast_synergy'] = df['REB_home'] * df['AST_REB_ratio_home']\n",
    "    df['scoring_x_defense'] = df['scoring_gap'] * df['defense_gap']\n",
    "    df['log_shooting_var_gap'] = np.log1p((df['FG_PCT_home'] - df['FG_PCT_away'])**2)\n",
    "    df['win_pct_gap_cubed'] = df['win_pct_gap'] ** 3\n",
    "\n",
    "    # Overall signal aggregation\n",
    "    df['overall_team_form'] = (\n",
    "        df['win_pct_gap'] +\n",
    "        df['scoring_gap'] -\n",
    "        df['defense_gap'] +\n",
    "        df['home_shooting_synergy'] -\n",
    "        df['away_shooting_synergy']\n",
    "    )\n",
    "\n",
    "    # Binning features\n",
    "    df['binned_momentum'] = pd.qcut(df['momentum_score'], q=4, labels=False, duplicates='drop')\n",
    "    df['binned_fg_home'] = pd.qcut(df['FG_PCT_home'], q=4, labels=False, duplicates='drop')\n",
    "    df['binned_reb_gap'] = pd.qcut(df['REB_home_minus_away'], q=4, labels=False, duplicates='drop')\n",
    "    df['binned_log_ast'] = pd.qcut(df['log_AST_home'], q=4, labels=False, duplicates='drop')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ab100d38-5d6c-457a-8349-5417e8103b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: final_feature_dataset, shape: (26058, 104)\n",
      "Skipped: games_details_processed.csv (no game structure)\n",
      "Skipped: games_processed.csv (no game structure)\n",
      "Skipped: games_with_rolling_metrics.csv (no game structure)\n",
      "Skipped: players_processed.csv (no game structure)\n",
      "Skipped: ranking_processed.csv (no game structure)\n",
      "Skipped: teams_processed.csv (no game structure)\n",
      "Skipped: team_metrics.csv (no game structure)\n"
     ]
    }
   ],
   "source": [
    "# Load processed CSVs\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    result = engineer_features(df)\n",
    "    if result is not None:\n",
    "        name = file.stem\n",
    "        processed_dfs[name] = result\n",
    "        result.to_csv(output_dir / f\"engineered_{name}.csv\", index=False)\n",
    "        print(f\"Processed: {name}, shape: {result.shape}\")\n",
    "    else:\n",
    "        print(f\"Skipped: {file.name} (no game structure)\")\n",
    "\n",
    "df_all = pd.concat(processed_dfs.values(), ignore_index=True)\n",
    "if 'GAME_ID' in df_all.columns:\n",
    "    df_all = df_all[df_all['GAME_ID'].notna()]\n",
    "\n",
    "# Drop unrelated player/team metadata\n",
    "irrelevant_cols = [\n",
    "    'PLAYER_NAME', 'PLAYER_ID', 'MIN', 'FGA', 'TEAM_CITY', 'TEAM_NAME', \n",
    "    'ARENA', 'OWNER', 'COMMENT', 'HEADCOACH', 'DLEAGUEAFFILIATION',\n",
    "    'LEAGUE_ID', 'SEASON_ID', 'TEAM_ABBREVIATION', 'TEAM', 'ROAD_RECORD',\n",
    "    'HOME_RECORD', 'GENERALMANAGER', 'ABBREVIATION', 'MAX_YEAR', 'MIN_YEAR',\n",
    "    'YEARFOUNDED', 'CITY', 'ARENACAPACITY', 'RETURNTOPLAY'\n",
    "]\n",
    "df_all = df_all.drop(columns=[col for col in irrelevant_cols if col in df_all.columns])\n",
    "\n",
    "leaky_cols = ['PTS_home', 'PTS_away']\n",
    "df_all = df_all.drop(columns=[col for col in leaky_cols if col in df_all.columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "99694007-57c1-4e97-af5a-0225624ad5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final dataset saved to: engineered_data\\engineered_final_feature_dataset.csv, shape: (26058, 97)\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "final_path = output_dir / \"engineered_final_feature_dataset.csv\"\n",
    "df_all.to_csv(final_path, index=False)\n",
    "print(f\"\\n Final dataset saved to: {final_path}, shape: {df_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "39a6129c-4994-48f8-af1d-82927a355c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All engineered data files saved to engineered_data\n",
      "Feature visualizations saved to figures\\engineered_features\n"
     ]
    }
   ],
   "source": [
    "if 'final_feature_dataset' in processed_dfs:\n",
    "    main_df = processed_dfs['final_feature_dataset']\n",
    "    \n",
    "    available_features = [f for f in all_new_features if f in main_df.columns]\n",
    "    \n",
    "    feature_batches = [available_features[i:i+9] for i in range(0, len(available_features), 9)]\n",
    "    \n",
    "    for i, feature_batch in enumerate(feature_batches):\n",
    "        if not feature_batch:\n",
    "            continue\n",
    "            \n",
    "        plt.figure(figsize=(15, 15))\n",
    "        for j, feature in enumerate(feature_batch):\n",
    "            plt.subplot(3, 3, j+1)\n",
    "            try:\n",
    "                sns.histplot(main_df[feature].dropna(), kde=True)\n",
    "                plt.title(feature)\n",
    "            except:\n",
    "                plt.title(f\"{feature} (error plotting)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figures_dir / f\"engineered_features_batch_{i+1}.png\")\n",
    "        plt.close()\n",
    "    \n",
    "    target_variables = ['HOME_TEAM_WINS', 'PTS_home', 'PTS_away', 'home_win']\n",
    "    for target in target_variables:\n",
    "        if target in main_df.columns:\n",
    "            target_features = [f for f in available_features if f in main_df.columns]\n",
    "            if target_features:\n",
    "                try:\n",
    "                    corr_with_target = main_df[target_features].corrwith(main_df[target]).abs().sort_values(ascending=False)\n",
    "                    \n",
    "                    plt.figure(figsize=(12, min(20, len(corr_with_target))))\n",
    "                    sns.barplot(x=corr_with_target.values, y=corr_with_target.index)\n",
    "                    plt.title(f'Engineered Features Correlation with {target}')\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig(figures_dir / f\"engineered_feature_correlations_{target}.png\")\n",
    "                    plt.close()\n",
    "                    \n",
    "                    print(f\"\\nTop 10 engineered features by correlation with {target}:\")\n",
    "                    for feature, corr in corr_with_target.head(10).items():\n",
    "                        print(f\"- {feature}: {corr:.4f}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating correlations with {target}: {e}\")\n",
    "\n",
    "print(f\"\\nAll engineered data files saved to {output_dir}\")\n",
    "print(f\"Feature visualizations saved to {figures_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625556f7-5437-4dab-9864-b469e32f9d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
